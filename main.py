import cv2
import mediapipe as mp
import torch
import numpy as np
import mujoco
import mujoco.viewer
from collections import deque
import time
import threading
from common.models import load_gesture_mlp
from common.strategy import get_winning_move

# åè¯è§£é‡Šï¼ˆå°ç™½å‹å¥½ï¼‰ï¼š
# - MediaPipeï¼šè°·æ­Œçš„è§†è§‰ AI åº“ï¼Œèƒ½ä»æ‘„åƒå¤´ç”»é¢ä¸­æå–â€œæ‰‹éƒ¨å…³é”®ç‚¹â€ã€‚
# - å…³é”®ç‚¹(Landmark)ï¼šæ‰‹æŒ‡å…³èŠ‚ç­‰ä½ç½®çš„åæ ‡ç‚¹ï¼Œæ¯ç‚¹å« x/y/zï¼Œåˆè®¡ 21Ã—3=63 ç»´ã€‚
# - å¼ é‡(Tensor)ï¼šPyTorch çš„å¤šç»´æ•°ç»„æ ¼å¼ï¼Œé€‚åˆåšç¥ç»ç½‘ç»œè®¡ç®—ã€‚
# - MLPï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰ï¼šåŸºç¡€ç¥ç»ç½‘ç»œï¼Œç”±â€œçº¿æ€§å±‚ + æ¿€æ´»å±‚â€å †å ï¼Œç”¨äºåˆ†ç±»æ‰‹åŠ¿ã€‚
# - MuJoCoï¼šç‰©ç†ä»¿çœŸå¼•æ“ï¼Œæ¨¡æ‹Ÿæœºæ¢°ç»“æ„çš„è¿åŠ¨ä¸ç¢°æ’ï¼›æœ¬é¡¹ç›®ç”¨å®ƒæ¥â€œåŠ¨æ‰‹æŒ‡â€ã€‚
# - qpos / qvelï¼šMuJoCo ä¸­å…³èŠ‚çš„â€œä½ç½®æ•°ç»„/é€Ÿåº¦æ•°ç»„â€ï¼Œåˆ†åˆ«è¡¨ç¤ºè§’åº¦å’Œè§’é€Ÿåº¦ã€‚
# - dt(m.opt.timestep)ï¼šæ¯æ¬¡ç‰©ç†ä»¿çœŸçš„â€œæ—¶é—´æ­¥é•¿â€ï¼Œä¾‹å¦‚ 0.002 ç§’/æ­¥ã€‚
# - viewerï¼šMuJoCo è‡ªå¸¦çš„æ¸²æŸ“çª—å£ï¼Œç”¨æ¥å¯è§†åŒ–æ¨¡å‹çš„å½“å‰å§¿æ€ã€‚
# æ–‡ä»¶ç”¨é€”ï¼šä»¿çœŸå…¥å£ï¼Œå°†æ‰‹åŠ¿æ˜ å°„åˆ°æœºæ¢°è‡‚åŠ¨ä½œ
# æœ€åä¿®æ”¹ï¼š2025-12-04
# ä¸»è¦åŠŸèƒ½ï¼š
# - è¯»å–æ¨¡å‹æ–‡ä»¶ rps_mlp.pth
# - è¯»å–ä»¿çœŸæ¨¡å‹ adam_u.xml
# - æ‘„åƒå¤´é‡‡é›†ä¸æ‰‹åŠ¿è¯†åˆ«
# - å¿…èƒœç­–ç•¥æ˜ å°„ä¸ç‰©ç†ä»¿çœŸæ¸²æŸ“
# é‡è¦ç»„ä»¶ï¼šThreadedCameraã€RealisticServoControllerã€run_simulation
# ä½¿ç”¨è¯´æ˜ï¼šä»¿çœŸéœ€æ±‚è¿è¡Œ main.pyï¼›ä»…æµ‹ç­–ç•¥è¿è¡Œ realtime.pyã€‚
# ==========================================
# 1. æé€Ÿé…ç½®
# ==========================================
XML_PATH = "adam_u.xml"
MODEL_PATH = "rps_mlp.pth"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# âš¡ SERVO_SPEEDï¼šæˆ‘ä»¬ä¸ºâ€œè™šæ‹Ÿèˆµæœºâ€è®¾å®šçš„æœ€å¤§è§’é€Ÿåº¦(å¼§åº¦/ç§’)ï¼Œæ•°å€¼è¶Šå¤§æ‰‹æŒ‡è¶Šå¿«ã€‚
SERVO_SPEED = 20.0 
# âš¡ ç›¸æœºåˆ†è¾¨ç‡ï¼šè¶Šä½å¤„ç†è¶Šå¿«ï¼Œ640x480 æ˜¯å¸¸è§çš„æŠ˜ä¸­æ–¹æ¡ˆã€‚
CAM_WIDTH, CAM_HEIGHT = 640, 480

# å…³èŠ‚ä¸åŠ¨ä½œé…ç½®ï¼š
# - BEND_VAL / STRAIGHT_VALï¼šæ‰‹æŒ‡â€œå¼¯æ›²/ä¼¸ç›´â€æ—¶çš„ç›®æ ‡è§’åº¦ï¼ˆæ­¤å¤„ç”¨ 1.0/0.0 ç®€åŒ–ï¼‰ã€‚
BEND_VAL = 1.0  
STRAIGHT_VAL = 0.0
FINGER_JOINTS = {
    "thumb":  ["R_thumb_MCP_joint1", "R_thumb_MCP_joint2", "R_thumb_PIP_joint", "R_thumb_DIP_joint"],
    "index":  ["R_index_MCP_joint", "R_index_DIP_joint"],
    "middle": ["R_middle_MCP_joint", "R_middle_DIP_joint"],
    "ring":   ["R_ring_MCP_joint", "R_ring_DIP_joint"],
    "pinky":  ["R_pinky_MCP_joint", "R_pinky_DIP_joint"]
}
# è§£é‡Šï¼š
# - MCP / PIP / DIPï¼šè§£å‰–å­¦åç§°ï¼Œåˆ†åˆ«æ˜¯æŒæŒ‡å…³èŠ‚/è¿‘æŒ‡é—´å…³èŠ‚/è¿œæŒ‡é—´å…³èŠ‚ï¼›æ‹‡æŒ‡ç»“æ„ç•¥æœ‰ä¸åŒã€‚
ARM_POSE = {"shoulderPitch_Right": -0.5, "elbow_Right": -1.0, "wristPitch_Right": 0.0}
# è§£é‡Šï¼š
# - shoulderPitch/elbow/wristPitchï¼šå³è‡‚çš„ä¸‰ä¸ªä¸»è¦å…³èŠ‚åï¼›è´Ÿå€¼ä»£è¡¨æŸæ–¹å‘å¼¯æ›²ï¼ˆå•ä½ï¼šå¼§åº¦ï¼‰ã€‚
GESTURES = {
    "rock":     {"thumb": 1, "index": 1, "middle": 1, "ring": 1, "pinky": 1},
    "paper":    {"thumb": 0, "index": 0, "middle": 0, "ring": 0, "pinky": 0},
    "scissors": {"thumb": 1, "index": 0, "middle": 0, "ring": 1, "pinky": 1},
    "waiting":  {"thumb": 0, "index": 0, "middle": 0, "ring": 0, "pinky": 0} 
}

# ==========================================
# 2. å¤šçº¿ç¨‹æ‘„åƒå¤´ç±» (æ ¸å¿ƒä¼˜åŒ–)
# ==========================================
class ThreadedCamera:
    """å¤šçº¿ç¨‹æ‘„åƒå¤´è¯»å–å™¨ï¼šåå°æ‹‰æµï¼Œå‰å°æ‹¿å‰¯æœ¬ï¼Œé™ä½è¯»å–é˜»å¡ä¸æ’•è£‚"""
    def __init__(self, src=0):
        self.capture = cv2.VideoCapture(src)
        self.capture.set(cv2.CAP_PROP_FRAME_WIDTH, CAM_WIDTH)
        self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, CAM_HEIGHT)
        # å°è¯•è®¾ç½® FPS ä¸º 60 (å–å†³äºæ‘„åƒå¤´æ˜¯å¦æ”¯æŒ)
        self.capture.set(cv2.CAP_PROP_FPS, 60)
        
        self.status, self.frame = self.capture.read()
        self.stop_event = False
        self.lock = threading.Lock()
        
        # å¯åŠ¨åå°çº¿ç¨‹
        self.thread = threading.Thread(target=self.update, args=())
        self.thread.daemon = True
        self.thread.start()

    def update(self):
        """åå°çº¿ç¨‹å¾ªç¯ï¼šæŒç»­è¯»å–æœ€æ–°å¸§å¹¶æ›´æ–°çŠ¶æ€"""
        while not self.stop_event:
            status, frame = self.capture.read()
            if status:
                with self.lock:
                    self.frame = frame
                    self.status = status
            else:
                self.stop_event = True

    def get_frame(self):
        """è¿”å›ä¸€å¸§çš„å®‰å…¨å‰¯æœ¬ï¼Œé¿å…ä¸Šå±‚ä¿®æ”¹åº•å±‚ç¼“å†²å¯¼è‡´ç«äº‰"""
        with self.lock:
            return self.status, self.frame.copy() # è¿”å›å‰¯æœ¬ä»¥é˜²ç«äº‰

    def release(self):
        """åœæ­¢åå°çº¿ç¨‹å¹¶é‡Šæ”¾æ‘„åƒå¤´èµ„æº"""
        self.stop_event = True
        self.thread.join()
        self.capture.release()

# ==========================================
# 3. é€»è¾‘ä¸æ¨¡å‹ï¼ˆç»Ÿä¸€ä» common å¯¼å…¥ï¼‰
# ==========================================

# ==========================================
# 4. ä»¿çœŸæ§åˆ¶å™¨
# ==========================================
class RealisticServoController:
    """MuJoCo å…³èŠ‚æ§åˆ¶å™¨ï¼šç»´æŠ¤ç›®æ ‡ `qpos` å¹¶ä»¥æœ€å¤§è§’é€Ÿåº¦é€¼è¿‘ç›®æ ‡

    æœ¯è¯­è§£é‡Šï¼š
    - mj_name2idï¼šé€šè¿‡åå­—æŸ¥æ‰¾ MuJoCo å¯¹è±¡ï¼ˆè¿™é‡Œæ˜¯â€œå…³èŠ‚â€ï¼‰çš„å†…éƒ¨ç¼–å· idã€‚
    - jnt_qposadrï¼šæ¯ä¸ªå…³èŠ‚åœ¨ `qpos`ï¼ˆä½ç½®æ•°ç»„ï¼‰ä¸­çš„èµ·å§‹ä¸‹æ ‡åœ°å€ã€‚
    - qposï¼šæ‰€æœ‰å…³èŠ‚çš„â€œä½ç½®â€ï¼ˆè§’åº¦ï¼‰é›†åˆï¼›qvelï¼šæ‰€æœ‰å…³èŠ‚çš„â€œé€Ÿåº¦â€ï¼ˆè§’é€Ÿåº¦ï¼‰ã€‚
    - ç›®æ ‡è¡¨(target_qpos)ï¼šæˆ‘ä»¬å¸Œæœ›æ¯ä¸ªå…³èŠ‚åˆ°è¾¾çš„è§’åº¦ï¼Œç”¨äºæ¸è¿›é€¼è¿‘å®ç°â€œå¹³æ»‘ç§»åŠ¨â€ã€‚
    """
    def __init__(self, model, data):
        self.model = model
        self.data = data
        self.joint_ids = {}
        self.target_qpos = {}
        
        for finger, joint_names in FINGER_JOINTS.items():
            ids = []
            for name in joint_names:
                jid = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)
                if jid != -1:
                    ids.append(jid)
                    addr = model.jnt_qposadr[jid]
                    self.target_qpos[addr] = data.qpos[addr]
            self.joint_ids[finger] = ids
            
        self.arm_ids = {}
        for name in ARM_POSE.keys():
            jid = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)
            if jid != -1: self.arm_ids[name] = jid

    def set_initial_pose(self):
        """è®¾å®šåˆå§‹å³è‡‚å§¿æ€å¹¶å‰å‘è®¡ç®—ä¸€æ¬¡ï¼Œä½¿ä»¿çœŸçŠ¶æ€ä¸€è‡´

        è§£é‡Šï¼š
        - mj_forwardï¼šè®© MuJoCo æ ¹æ®å½“å‰ `qpos`/`qvel` é‡æ–°è®¡ç®—èº¯ä½“çŠ¶æ€ï¼ˆåˆšä½“å˜æ¢ç­‰ï¼‰ã€‚
        - å°†æµ®åŠ¨åº•åº§ z åæ ‡è®¾ä¸º 1.0ï¼ŒæŠŠæ¨¡å‹â€œæŠ¬é«˜â€åˆ°æ‘„åƒæœºæ›´æ˜“è§‚å¯Ÿçš„é«˜åº¦ã€‚
        """
        for name, angle in ARM_POSE.items():
            if name in self.arm_ids:
                self.data.qpos[self.model.jnt_qposadr[self.arm_ids[name]]] = angle
        if self.model.nq >= 7: self.data.qpos[2] = 1.0 
        mujoco.mj_forward(self.model, self.data)

    def apply_gesture(self, gesture_name):
        """æ ¹æ®æ‰‹åŠ¿é…ç½®æ›´æ–°å„æ‰‹æŒ‡å…³èŠ‚çš„ç›®æ ‡è§’åº¦(å¼¯æ›²/ä¼¸ç›´)"""
        target_config = GESTURES.get(gesture_name, GESTURES["waiting"])
        for finger, is_bent in target_config.items():
            target_angle = BEND_VAL if is_bent else STRAIGHT_VAL
            if finger in self.joint_ids:
                for jid in self.joint_ids[finger]:
                    self.target_qpos[self.model.jnt_qposadr[jid]] = target_angle

    def update_servos(self, dt):
        """å°†å½“å‰è§’åº¦ä»¥æ­¥é•¿é™åˆ¶ `SERVO_SPEED*dt` æ¨è¿›åˆ°ç›®æ ‡è§’åº¦ï¼Œå¾—åˆ°å¹³æ»‘æ§åˆ¶

        è§£é‡Šï¼š
        - step_limitï¼šæ¯ä¸€ä»¿çœŸæ­¥å…è®¸çš„æœ€å¤§è§’åº¦å˜åŒ–ï¼Œé˜²æ­¢â€œç¬é—´è·³å˜â€ã€‚
        - np.clipï¼šæŠŠå˜åŒ–é‡é™åˆ¶åœ¨ [-step_limit, +step_limit] èŒƒå›´å†…ï¼Œå®ç°â€œåŒ€é€Ÿé€¼è¿‘â€ã€‚
        """
        for addr, target in self.target_qpos.items():
            current = self.data.qpos[addr]
            step_limit = SERVO_SPEED * dt
            diff = target - current
            if abs(diff) > 1e-4:
                self.data.qpos[addr] = current + np.clip(diff, -step_limit, step_limit)

# ==========================================
# 5. ä¸»ç¨‹åº
# ==========================================
def run_simulation():
    """ä¸»å¾ªç¯ï¼šæ‘„åƒå¤´é‡‡é›† â†’ å…³é”®ç‚¹æ¨ç† â†’ å¿…èƒœæ‰‹åŠ¿ â†’ ä»¿çœŸæ­¥è¿›/æ¸²æŸ“

    è§£é‡Šï¼š
    - viewer.launch_passiveï¼šä»¥â€œè¢«åŠ¨æ¨¡å¼â€å¯åŠ¨æ¸²æŸ“çª—å£ï¼ˆæˆ‘ä»¬è‡ªå·±æ§åˆ¶ mj_step å’Œ viewer.syncï¼‰ã€‚
    - m.opt.timestep(dt)ï¼šæ¯æ¬¡ä»¿çœŸæ¨è¿›çš„æ—¶é—´é‡ï¼Œå½±å“â€œé€Ÿåº¦â€å’Œâ€œå¹³æ»‘ç¨‹åº¦â€ã€‚
    - sim_time_budgetï¼šç»™ç‰©ç†å¼•æ“çš„æ—¶é—´é…é¢ï¼ˆä¾‹å¦‚ 5msï¼‰ï¼Œé¿å…é˜»å¡è§†è§‰æ¨ç†ã€‚
    """
    # Load Modelï¼ˆç»Ÿä¸€æ¥å£ï¼‰
    net, classes = load_gesture_mlp(MODEL_PATH, DEVICE)

    # Init MediaPipe (CPU Mode, but optimized)
    mp_hands = mp.solutions.hands
    # âš ï¸ é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼šè®©å®ƒæ›´æ—©åœ°æ£€æµ‹åˆ°æ‰‹ï¼Œå“ªæ€•æœ‰ç‚¹æ¨¡ç³Š
    hands = mp_hands.Hands(
        max_num_hands=1, 
        min_detection_confidence=0.3, 
        min_tracking_confidence=0.3
    )

    # Init MuJoCo
    m = mujoco.MjModel.from_xml_path(XML_PATH)
    d = mujoco.MjData(m)
    m.opt.gravity = (0, 0, 0)
    controller = RealisticServoController(m, d)
    controller.set_initial_pose()

    # Init Threaded Camera
    print("ğŸ¥ å¯åŠ¨å¤šçº¿ç¨‹æ‘„åƒå¤´é‡‡é›†...")
    cam = ThreadedCamera(0)
    time.sleep(1.0) # ç­‰å¾…æ‘„åƒå¤´é¢„çƒ­

    current_robot_move = "waiting"
    dt = m.opt.timestep 
    
    # FPS Calculation
    fps_start = time.time()
    frames = 0
    inference_time = 0

    print("ğŸš€ æé€Ÿæ¨¡å¼å·²å¯åŠ¨ - è¯·æµ‹è¯•")

    with mujoco.viewer.launch_passive(m, d) as viewer:
        while viewer.is_running() and cam.status:
            loop_start = time.time()
            
            # 1. è·å–æœ€æ–°å¸§ (éé˜»å¡)
            ret, frame = cam.get_frame()
            if not ret: break
            
            # 2. å›¾åƒå¤„ç†
            frame_flip = cv2.flip(frame, 1)
            rgb = cv2.cvtColor(frame_flip, cv2.COLOR_BGR2RGB)
            
            t0 = time.time()
            result = hands.process(rgb)
            # è§£é‡Šï¼šMediaPipe å¯¹å½“å‰ç”»é¢åšæ‰‹éƒ¨æ£€æµ‹ä¸è·Ÿè¸ªï¼Œè¿”å›å…³é”®ç‚¹é›†åˆã€‚
            inference_time = (time.time() - t0) * 1000 # ms
            
            user_move = "waiting"
            if result.multi_hand_landmarks:
                landmarks = []
                for lm in result.multi_hand_landmarks[0].landmark:
                    landmarks.extend([lm.x, lm.y, lm.z])
                
                # MLP Inference
                x_tensor = torch.tensor(landmarks, dtype=torch.float32).to(DEVICE).unsqueeze(0)
                # è§£é‡Šï¼šæŠŠ 63 ç»´æ•°å­—æ‰“åŒ…æˆâ€œæ‰¹é‡=1â€çš„å¼ é‡ï¼Œé€è¿›ç¥ç»ç½‘ç»œã€‚
                with torch.no_grad():
                    preds = net(x_tensor)
                    # æ ¸å¿ƒé€»è¾‘ï¼šåªè¦ç½‘ç»œè¾“å‡ºå¯¹æŸç±»æ›´å€¾å‘ï¼ˆåˆ†æ•°æ›´é«˜ï¼‰ï¼Œç«‹åˆ»å½“ä½œè¯¥æ‰‹åŠ¿ä½¿ç”¨ã€‚
                    user_move = classes[torch.argmax(preds, dim=1).item()]

            # 3. æ ¸å¿ƒï¼šæ ¹æ®ç©å®¶æ‰‹åŠ¿è®¡ç®—æœºå™¨äººå¿…èƒœæ‰‹åŠ¿ï¼Œå¹¶æ›´æ–°ç›®æ ‡
            winning_move = get_winning_move(user_move)
            if winning_move != current_robot_move:
                current_robot_move = winning_move
                controller.apply_gesture(current_robot_move)

            # 4. ç‰©ç†æ­¥è¿› (è¿½èµ¶æ—¶é—´)
            # å°½é‡ä¿æŒç‰©ç†å¾ªç¯ä¸é˜»å¡è§†è§‰å¾ªç¯
            sim_time_budget = 0.005 # ç»™ç‰©ç†å¼•æ“åˆ†é… 5msï¼ˆæ—¶é—´é…é¢ï¼‰
            sim_start = time.time()
            while time.time() - sim_start < sim_time_budget:
                controller.update_servos(dt)
                d.qvel[:] = 0           # è§£é‡Šï¼šæŠŠè§’é€Ÿåº¦æ¸…é›¶ï¼Œé¿å…ç´¯ç§¯é€Ÿåº¦å¯¼è‡´æŠ–åŠ¨æˆ–å¤±ç¨³ã€‚
                d.qpos[0:3] = [0,0,1]   # è§£é‡Šï¼šå›ºå®šåº•åº§ä½ç½®ï¼ˆx,y,zï¼‰ï¼Œè®©æ¨¡å‹ä¸æ¼‚ç§»ã€‚
                mujoco.mj_step(m, d)    # è§£é‡Šï¼šæ¨è¿›ä¸€æ¬¡ç‰©ç†ä»¿çœŸæ­¥ï¼ˆåŸºäºå½“å‰ qpos/qvelï¼‰ã€‚
            
            viewer.sync()  # è§£é‡Šï¼šåˆ·æ–°æ¸²æŸ“çª—å£åˆ°æœ€æ–°ä»¿çœŸçŠ¶æ€ã€‚
            
            # 5. ä¿¡æ¯æ˜¾ç¤º
            frames += 1
            if time.time() - fps_start >= 1.0:
                fps = frames / (time.time() - fps_start)
                print(f"FPS: {fps:.1f} | Inference: {inference_time:.1f}ms")
                frames = 0
                fps_start = time.time()

            cv2.putText(
                frame_flip,
                f"User: {user_move}",
                (10, 40),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (0, 255, 0),
                2,
            )
            cv2.putText(
                frame_flip,
                f"Robot: {current_robot_move}",
                (10, 80),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (0, 0, 255),
                2,
            )
            cv2.putText(
                frame_flip,
                f"Inference: {inference_time:.1f}ms",
                (10, 460),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (200, 200, 0),
                1,
            )
            
            cv2.imshow("Fast Sim", frame_flip)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    cam.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    run_simulation()
