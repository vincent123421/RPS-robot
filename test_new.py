import cv2
import mediapipe as mp
import torch
import numpy as np
from collections import deque
import time # ç”¨äºæ¨¡æ‹Ÿä¸²å£å»¶è¿Ÿï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´ç²¾ç¡®çš„æ§åˆ¶

# --------------------------
# é…ç½®åŒº
# --------------------------
MODEL_PATH = "rps_mlp.pth"  # ä½ è®­ç»ƒçš„æ¨¡å‹è·¯å¾„
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
SMOOTH_WINDOW = 1  # âš ï¸ å…³é”®ï¼šå‡å°å¹³æ»‘çª—å£åˆ° 1 æˆ– 2ï¼Œä»¥è¿½æ±‚æœ€ä½å»¶è¿Ÿ
# --------------------------

# --------------------------
# æ¨¡å‹å®šä¹‰ï¼ˆå’Œ train_mlp.py ä¿æŒä¸€è‡´ï¼‰
# --------------------------
class RPS_MLP(torch.nn.Module):
    def __init__(self, input_size=63, hidden_size=128, num_classes=3):
        super().__init__()
        self.net = torch.nn.Sequential(
            torch.nn.Linear(input_size, hidden_size),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_size, hidden_size),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_size, num_classes)
        )

    def forward(self, x):
        return self.net(x)

# --------------------------
# å¿…èƒœé€»è¾‘å‡½æ•°
# --------------------------
def get_winning_move(user_move):
    """æ ¹æ®ç”¨æˆ·çš„åŠ¨ä½œï¼Œè¿”å›æœºå™¨äººå¿…èƒœçš„åŠ¨ä½œ"""
    if user_move == 'rock':
        return 'paper'
    elif user_move == 'paper':
        return 'scissors'
    elif user_move == 'scissors':
        return 'rock'
    return "waiting" # æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ‰‹åŠ¿æ—¶ï¼Œä¿æŒç­‰å¾…çŠ¶æ€

# --------------------------
# ç¡¬ä»¶æŒ‡ä»¤å‘é€å‡½æ•°ï¼ˆé‡ç‚¹æ›¿æ¢éƒ¨åˆ†ï¼‰
# --------------------------
# âš ï¸ æ³¨æ„ï¼šä½ éœ€è¦å°†æ­¤å‡½æ•°ä¸­çš„ 'pass' å’Œ print æ›¿æ¢ä¸ºå®é™…çš„ä¸²å£æˆ–ç¡¬ä»¶é€šä¿¡ä»£ç 
# æ¯”å¦‚ä½¿ç”¨ `import serial` å¹¶é…ç½®ä½ çš„ä¸²å£å¯¹è±¡
def send_command(move):
    """
    å‘é€æŒ‡ä»¤ç»™èˆµæœºæ§åˆ¶æ¿ã€‚
    move: æœºå™¨äººéœ€è¦å‡ºçš„æ‰‹åŠ¿ ('rock', 'paper', 'scissors', 'waiting')
    """
    if move == "waiting":
        # ä¿æŒæ‰‹åŠ¿ä¸å˜æˆ–å½’ä½
        # print(f"-> ä¿æŒæˆ–å½’ä½æŒ‡ä»¤")
        pass
    else:
        # å®é™…æ“ä½œ: serial_port.write(f"{move}\n".encode())
        print(f"ğŸ¤– **å‘é€æŒ‡ä»¤: å‡º {move}**")
        # æ¨¡æ‹Ÿä¸€ä¸ªå‘é€å’Œæ‰§è¡Œçš„å¾®å°å»¶è¿Ÿ
        # time.sleep(0.01) 
    return move

# --------------------------
# åŠ è½½æ¨¡å‹
# --------------------------
print("âœ… åŠ è½½æ¨¡å‹ä¸­...")
ckpt = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False)
model = RPS_MLP(input_size=63, hidden_size=128, num_classes=len(ckpt["classes"]))
model.load_state_dict(ckpt["model_state"])
model.to(DEVICE)
model.eval()
classes = list(ckpt["classes"])
print(f"âœ… æ¨¡å‹å·²åŠ è½½ï¼Œç±»åˆ«ï¼š{classes}")

# --------------------------
# åˆå§‹åŒ– MediaPipe å’ŒçŠ¶æ€å˜é‡
# --------------------------
mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils
# è°ƒä½ min_detection_confidence ä»¥æ›´å¿«åœ°è¯†åˆ«æ­£åœ¨å½¢æˆçš„æ‰‹
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.4) 

pred_buffer = deque(maxlen=SMOOTH_WINDOW)
# çŠ¶æ€å˜é‡åˆå§‹åŒ–
current_robot_move = "waiting" # æœºå™¨äººå½“å‰å·²ç»æ‰§è¡Œçš„åŠ¨ä½œæŒ‡ä»¤

# --------------------------
# æ‘„åƒå¤´å¾ªç¯
# --------------------------
cap = cv2.VideoCapture(0)
print("ğŸ® å¯åŠ¨å¿…èƒœè¯†åˆ«æ¨¡å¼ï¼ŒæŒ‰ q é€€å‡º")
frame_count = 0
start_time = time.time()

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb)

    user_move = "waiting" # ç”¨æˆ·å½“å‰é¢„æµ‹åˆ°çš„æ‰‹åŠ¿
    
    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # æå–å…³é”®ç‚¹åæ ‡
            landmarks = []
            for lm in hand_landmarks.landmark:
                landmarks.extend([lm.x, lm.y, lm.z])

            # è½¬ä¸ºTensorå¹¶é¢„æµ‹
            x = torch.tensor(landmarks, dtype=torch.float32).to(DEVICE).unsqueeze(0)
            with torch.no_grad():
                preds = model(x)
                probs = torch.nn.functional.softmax(preds, dim=1)
                label_idx = torch.argmax(probs, dim=1).item()
                conf = probs[0, label_idx].item()
                predicted_label = classes[label_idx]

            # åº”ç”¨å¹³æ»‘ï¼ˆSMOOTH_WINDOW=1 æ—¶ç›¸å½“äºæ— å¹³æ»‘ï¼‰
            pred_buffer.append(predicted_label)
            if len(pred_buffer) == SMOOTH_WINDOW:
                # ç®€å•å¤šæ•°æŠ•ç¥¨æ¥å¹³æ»‘ï¼ˆå³ä½¿çª—å£ä¸º 1 ä¹Ÿèƒ½å·¥ä½œï¼‰
                user_move = max(set(pred_buffer), key=pred_buffer.count)
                
            # æ˜¾ç¤ºç»“æœ
            cv2.putText(frame, f"You: {user_move} ({conf*100:.1f}%)",
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
            
    else:
        pred_buffer.clear()
        user_move = "waiting"

    # ----------------------------------------------------
    # æ ¸å¿ƒä½œå¼Š/æŒ‡ä»¤å‘é€é€»è¾‘ï¼šçŠ¶æ€å˜æ›´è§¦å‘
    # ----------------------------------------------------
    
    # 1. è®¡ç®—æœºå™¨äººå¿…èƒœæ‰‹åŠ¿
    required_robot_move = get_winning_move(user_move)

    # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦å‘é€æ–°æŒ‡ä»¤
    if required_robot_move != current_robot_move:
        # ç”¨æˆ·çš„é¢„æµ‹åŠ¨ä½œå‘ç”Ÿäº†å˜åŒ– (ä¾‹å¦‚ä» waiting -> rock, æˆ– rock -> paper)
        # ç«‹å³å‘é€æ–°çš„å¿…èƒœæŒ‡ä»¤
        current_robot_move = send_command(required_robot_move)
    
    # æ˜¾ç¤ºæœºå™¨äººåŠ¨ä½œ
    cv2.putText(frame, f"Robot: {current_robot_move.upper()}",
                (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)

    # FPS è®¡ç®— (å¯é€‰ï¼Œç”¨äºç¡®è®¤ç³»ç»Ÿå»¶è¿Ÿ)
    frame_count += 1
    if frame_count % 30 == 0:
        end_time = time.time()
        fps = 30 / (end_time - start_time)
        start_time = end_time
        cv2.putText(frame, f"FPS: {fps:.1f}", (500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    cv2.imshow("Janken Robot - Cheat Mode", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()